{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accessing IPython cluster clients and printing their ids to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "import ipyparallel as parallel\n",
    "\n",
    "clients = parallel.Client()\n",
    "clients.block = True  # use synchronous computations\n",
    "print(clients.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing mpi4py and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "from mpi4py import MPI\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing Convolution, you don't need to modify this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "\n",
    "def convolve_func(main, kernel, KERNEL_DIM, DIMx, DIMy, upper_pad, lower_pad):\n",
    "    num_pads = int((KERNEL_DIM - 1) / 2)\n",
    "    conv = np.zeros(main.shape, dtype=int)\n",
    "    main = np.concatenate((upper_pad, main, lower_pad))\n",
    "    for i in range(DIMy):\n",
    "        for j in range(DIMx):\n",
    "            for k in range(KERNEL_DIM):\n",
    "                for l in range(KERNEL_DIM):\n",
    "                    if j + l <= DIMx + 1 and i + k >= num_pads and i + k <= DIMy:\n",
    "                        conv[j * DIMy + i] += main[(j + l) * DIMy + i - num_pads + k] * kernel[k][l]\n",
    "    return conv\n",
    "\n",
    "\n",
    "def convolve_func(main, kernel):\n",
    "    DIMx, DIMy = main.shape\n",
    "    convDimX = DIMx - (kernel.shape[0] - 1)\n",
    "    convDimY = DIMy - (kernel.shape[1] - 1)\n",
    "    conv = np.empty([convDimX, convDimY], dtype='int64')\n",
    "    conv.fill(0)\n",
    "    for i in range(convDimX):\n",
    "        for j in range(convDimY):\n",
    "            for k in range(kernel.shape[0]):\n",
    "                for l in range(kernel.shape[1]):\n",
    "                    conv[i, j] += main[i + k, j + l] * kernel[k, l]\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 points: \n",
    "Load MPI communicator, get the total number of processes and rank of the process                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] total process number: 3, printing from process: 0\n",
      "[stdout:1] total process number: 3, printing from process: 1\n",
      "[stdout:2] total process number: 3, printing from process: 2\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "#and also print total number of processes and rank from each process\n",
    "comm = MPI.COMM_WORLD\n",
    "print(f'total process number: {comm.Get_size()}, printing from process: {comm.Get_rank()}')\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 points: \n",
    "Load or initialize data array and kernel array only in process 0(rank 0)                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "DIMx = 0\n",
    "DIMy = 0\n",
    "KERNEL_DIM = 0\n",
    "\n",
    "#Add a condition such that these intializations below should happen in only process 0\n",
    "if comm.Get_rank() == 0:\n",
    "    img = np.array(\n",
    "        [[3, 9, 5, 9], [1, 7, 4, 3], [2, 1, 6, 5], [3, 9, 5, 9], [1, 7, 4, 3], [2, 1, 6, 5], [3, 9, 5, 9], [1, 7, 4, 3],\n",
    "         [2, 1, 6, 5]])\n",
    "    kernel = np.array([[0, 1, 0], [0, 0, 0], [0, -1, 0]])\n",
    "    DIMx = img.shape[0]\n",
    "    DIMy = img.shape[1]\n",
    "    KERNEL_DIM = int(kernel.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 points: \n",
    "Broadcast data and kernel array sizes from process 0 to  all other processes                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#broadcast data and kernel array sizes (think why we are broadcasting sizes)\n",
    "DIMx = comm.bcast(DIMx, root=0)\n",
    "DIMy = comm.bcast(DIMy, root=0)\n",
    "KERNEL_DIM = comm.bcast(KERNEL_DIM, root=0)\n",
    "\n",
    "# print(img.shape)\n",
    "# print(DIMy)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize empty kernel array for all  processes except rank = 0, why we are not initialzing kernel array for rank 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "- Because rank0 keeps the original kernel array to be broadcasted to other process later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#initialize empty kernel array except for process 0(rank=0)\n",
    "if comm.Get_rank() != 0:\n",
    "    kernel = np.empty([KERNEL_DIM, KERNEL_DIM], dtype='int64')\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 points: \n",
    "Broadcast Kernel array from rank 0 to all other processes.                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#broadcast kernel array from rank 0 to all other processes\n",
    "comm.Bcast(kernel, root=0)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 points: \n",
    "Split the rows in data array equally and scatter them from process 0 to all other process. To split them \n",
    "equally, number of rows in the data array must be a integral multiple of number of processes. MPI has ways \n",
    "to send unequal chunks of data between processses. But for here you can do with equal number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#split and send data array to corresponding processses (you need to initialize a buffer to receive data from \n",
    "#process 0, similar to the random initializing done for kernel array)\n",
    "\n",
    "sendbuf = None\n",
    "if comm.Get_rank() == 0:\n",
    "    sendbuf = img\n",
    "inputData = np.empty([round(DIMx / comm.Get_size()), DIMy], dtype='int64')\n",
    "comm.Scatter(sendbuf, inputData, root=0)\n",
    "\n",
    "#Here does we initialize buffer for process 0 also, if so why?(Hint: because of the function we are using to send \n",
    "#and receieve data)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25 points: \n",
    "For convolution of kernel array and data array, you have to pass the kernel padding rows from one\n",
    "process to another. please see objective for more details. Send and Recieve rows from one process \n",
    "to other. Careful with the data size and tags you are sending and receiving should match otherwise\n",
    "commincator will wait for them indefintely.                                                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[[0 0 0 0]\n",
      " [3 9 5 9]\n",
      " [1 7 4 3]\n",
      " [2 1 6 5]]\n",
      "[stdout:1] \n",
      "[[3 9 5 9]\n",
      " [1 7 4 3]\n",
      " [2 1 6 5]]\n",
      "[stdout:2] \n",
      "[[3 9 5 9]\n",
      " [1 7 4 3]\n",
      " [2 1 6 5]\n",
      " [0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "#send padding rows from one process to other (carefully observe which process to send data to which process and\n",
    "# which process receives the data)\n",
    "\n",
    "if comm.Get_rank() == 0:\n",
    "    paddingFirst = np.zeros(DIMy)\n",
    "    sendArray = paddingFirst\n",
    "    comm.Send([sendArray, MPI.INT], dest=comm.Get_size() - 1, tag=33)\n",
    "\n",
    "    inputData = np.insert(inputData, 0, values=paddingFirst, axis=0)\n",
    "\n",
    "\n",
    "elif comm.Get_rank() == comm.Get_size() - 1:\n",
    "    receiveArray = np.empty(DIMy, dtype='int64')\n",
    "    comm.Recv(receiveArray, source=0, tag=33)\n",
    "\n",
    "    paddingLast = receiveArray\n",
    "    inputData = np.append(inputData, [paddingLast], axis=0)\n",
    "\n",
    "print(inputData)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why we are loading data into process 0 and broadcasting input data to all other processes? are there any other methods to load data into all processes (not for evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "1. Process 0 is playing the master role in the cluster. It is process 0's responsibility to coordinate and schedule data and tasks.\n",
    "2. Yes, data could be kept in a central database that every process could access. Or store the split data in to a distributed database allocated for each process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 points: \n",
    "Perform Convolution operation by calling convolve_func() provided for each of the process with \n",
    "corresponding rows as arguments.                                                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "sending to dest:1, tag:1\n",
      "receive from dest:1, tag:10\n",
      "[[-7 -4]\n",
      " [ 8 -1]\n",
      " [-2 -1]]\n",
      "[stdout:1] \n",
      "sending to dest:2, tag:12\n",
      "receive from dest:2, tag:21\n",
      "sending to dest:0, tag:10\n",
      "receive from dest:0, tag:1\n",
      "[[-6  2]\n",
      " [ 8 -1]\n",
      " [-2 -1]]\n",
      "[stdout:2] \n",
      "sending to dest:1, tag:21\n",
      "receive from dest:1, tag:12\n",
      "[[-6  2]\n",
      " [ 8 -1]\n",
      " [ 7  4]]\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "#convolution function arguments\n",
    "#main - data array (flattened array), only the part of the data array that is processed for each process\n",
    "#kernel - kernel array\n",
    "#DIMy - ColumnSize\n",
    "#Dimx - RowSize\n",
    "#upper_pad = upper padding row\n",
    "#lower_pad = lower padding row\n",
    "\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "if comm.rank != comm.Get_size() - 1:\n",
    "    sendArray = inputData[-1]\n",
    "    print(f'sending to dest:{rank + 1}, tag:{11 * rank + 1}')\n",
    "    comm.Send([sendArray, MPI.INT], dest=rank + 1, tag=11 * rank + 1)\n",
    "\n",
    "    receiveArray = np.empty(DIMy, dtype='int64')\n",
    "    receiveArray.fill(0)\n",
    "    comm.Recv(receiveArray, source=rank + 1, tag=11 * (rank + 1) - 1)\n",
    "    print(f'receive from dest:{rank + 1}, tag:{11 * (rank + 1) - 1}')\n",
    "    inputData = np.append(inputData, [receiveArray], axis=0)\n",
    "\n",
    "if rank != 0:\n",
    "    sendArray = inputData[0]\n",
    "    print(f'sending to dest:{rank - 1}, tag:{11 * rank - 1}')\n",
    "    comm.Send([sendArray, MPI.INT], dest=rank - 1, tag=11 * rank - 1)\n",
    "\n",
    "    receiveArray = np.empty(DIMy, dtype='int64')\n",
    "    receiveArray.fill(0)\n",
    "    comm.Recv(receiveArray, source=rank - 1, tag=11 * (rank - 1) + 1)\n",
    "    print(f'receive from dest:{rank - 1}, tag:{11 * (rank - 1) + 1}')\n",
    "    inputData = np.insert(inputData, 0, values=receiveArray, axis=0)\n",
    "\n",
    "convResult = convolve_func(inputData, kernel)\n",
    "print(convResult)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 points: \n",
    "Gather the computed convolutional matrix rows to process 0.                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] \n",
      "[[-7 -4]\n",
      " [ 8 -1]\n",
      " [-2 -1]\n",
      " [-6  2]\n",
      " [ 8 -1]\n",
      " [-2 -1]\n",
      " [-6  2]\n",
      " [ 8 -1]\n",
      " [ 7  4]]\n",
      "[stdout:1] None\n",
      "[stdout:2] None\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "#To receive data from all processes, process 0 should have a buffer\n",
    "\n",
    "size = comm.Get_size()\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "gatherSendArray = convResult.flatten()\n",
    "gatherReceiveArray = None\n",
    "if rank == 0:\n",
    "    gatherReceiveArray = np.empty([img.shape[0] + 2 - (kernel.shape[0] -1),\n",
    "                                   img.shape[1] - (kernel.shape[1] - 1)], dtype='int64')\n",
    "\n",
    "comm.Gather(gatherSendArray, gatherReceiveArray, root=0)\n",
    "\n",
    "print(gatherReceiveArray)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the flattened array to match input dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "#Reshape the collected array to the input image dimensions\n",
    "if rank == 0:\n",
    "    gatherReceiveArray = np.reshape(gatherReceiveArray, (-1, DIMx))\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5 points: \n",
    "Test to check sequential convolution and MPI based parallel convolution outputs                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[stdout:0] True\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "if rank == 0:\n",
    "    #main_grid is the actual input input image array that is flattened\n",
    "    #convolution function arguments\n",
    "    #main_grid - data array (flattened array)\n",
    "    #kernel - kernel array\n",
    "    #DIMy - ColumnSize\n",
    "    #Dimx - RowSize\n",
    "    #upper_pad = upper padding row\n",
    "    #lower_pad = lower padding row\n",
    "\n",
    "    #rename the below arguments according to your variable names\n",
    "\n",
    "    #Entire convolution in a single process\n",
    "    # conv1 = convolve_func(main_grid, kernel, KERNEL_DIM, DIMx, DIMy, upper_pad, upper_pad)\n",
    "    conv1 = convolve_func(np.concatenate(([np.zeros(DIMy, dtype='int64')], img, [np.zeros(DIMy, dtype='int64')])), kernel)\n",
    "    conv1 = np.reshape(conv1, (-1, DIMx))\n",
    "    #recvbuf is the convolution computed by parallel processes and gathered in process 0, \n",
    "    #if you named it different, modify that name below\n",
    "\n",
    "    #Checking with parallel convolution output\n",
    "    print(np.array_equal(conv1, gatherReceiveArray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
